{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1: Data Cleaning and Pre-processing"
      ],
      "metadata": {
        "id": "j3usE157tFTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hN-X3UUJrgoa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "foodgrain_file_path = '/content/drive/MyDrive/data visualization class/hw/foodgrainsproduction_fiscalyear.csv'\n",
        "foodgrain_data = pd.read_csv(foodgrain_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "RjoxpdRSrkr3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace special characters and non-numeric values with NaN\n",
        "non_numeric_values = ['$$$$', '%%%%%', '&&&', 'app', '(((', 'NA']\n",
        "foodgrain_data.replace(non_numeric_values, np.nan, inplace=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H_P7rBGtrnqk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns to numeric, forcing errors to NaN\n",
        "cols = foodgrain_data.columns.drop('F/Y')\n",
        "foodgrain_data[cols] = foodgrain_data[cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill missing values with forward fill and median replacement\n",
        "foodgrain_data.fillna(method='ffill', inplace=True)\n",
        "foodgrain_data.fillna(foodgrain_data.median(), inplace=True)\n",
        "\n",
        "print(foodgrain_data.head())\n",
        "print(foodgrain_data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XPkn6JorpRj",
        "outputId": "68e19673-d70f-44f6-9c97-507c5c966bce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    F/Y   Paddy   Maize   Wheat  Millet  Barley  Buckwheat\n",
            "0  1998  3710.0  1346.0  1086.0   291.0    32.0       10.0\n",
            "1  1999  4030.0  1445.0  1184.0   295.0    31.0       10.0\n",
            "2  2000  4216.0  1484.0  1158.0   283.0    30.0       10.0\n",
            "3  2001  4216.0  1511.0  1158.0   283.0    30.0       10.0\n",
            "4  2002  4133.0  1569.0  1344.0   283.0    32.0       10.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18 entries, 0 to 17\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   F/Y        18 non-null     int64  \n",
            " 1   Paddy      18 non-null     float64\n",
            " 2   Maize      18 non-null     float64\n",
            " 3   Wheat      18 non-null     float64\n",
            " 4   Millet     18 non-null     float64\n",
            " 5   Barley     18 non-null     float64\n",
            " 6   Buckwheat  18 non-null     float64\n",
            "dtypes: float64(6), int64(1)\n",
            "memory usage: 1.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate rows\n",
        "duplicates = foodgrain_data.duplicated()\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Bnz_3csHGX",
        "outputId": "639cdad6-501a-4dfc-b916-26f37c191f66"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows\n",
        "foodgrain_data = foodgrain_data.drop_duplicates()"
      ],
      "metadata": {
        "id": "R5mjroBTsI2H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that all duplicates have been removed\n",
        "duplicates = foodgrain_data.duplicated()\n",
        "print(f\"Number of duplicate rows after removal: {duplicates.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q0DOSzPsKE9",
        "outputId": "ee9ab831-38c0-41c8-8b1f-8d08defe877d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows after removal: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify outliers using the IQR method\n",
        "Q1 = foodgrain_data[cols].quantile(0.25)\n",
        "Q3 = foodgrain_data[cols].quantile(0.75)\n",
        "IQR = Q3 - Q1"
      ],
      "metadata": {
        "id": "hYVEHBRzsNAF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define outliers as rows outside 1.5 * IQR\n",
        "outliers = (foodgrain_data[cols] < (Q1 - 1.5 * IQR)) | (foodgrain_data[cols] > (Q3 + 1.5 * IQR))\n",
        "print(outliers.sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QITC2ZE3sOnP",
        "outputId": "84c27b87-d7ca-48c3-e314-480ee58e0f15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paddy        2\n",
            "Maize        0\n",
            "Wheat        0\n",
            "Millet       3\n",
            "Barley       1\n",
            "Buckwheat    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with outliers\n",
        "foodgrain_data = foodgrain_data[~outliers.any(axis=1)]\n",
        "\n",
        "print(foodgrain_data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_chSbSgzsRD0",
        "outputId": "778a0b59-f096-4a36-c586-6f215d79b77e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               F/Y        Paddy        Maize        Wheat      Millet  \\\n",
            "count    10.000000    10.000000    10.000000    10.000000   10.000000   \n",
            "mean   2003.600000  4208.100000  1652.300000  1349.800000  287.700000   \n",
            "std       3.204164   128.310777   153.914875   145.156467    6.183311   \n",
            "min    1999.000000  4023.000000  1445.000000  1158.000000  283.000000   \n",
            "25%    2001.250000  4152.000000  1525.500000  1224.000000  283.000000   \n",
            "50%    2003.500000  4212.500000  1642.500000  1365.500000  284.000000   \n",
            "75%    2005.750000  4271.500000  1798.500000  1430.000000  291.000000   \n",
            "max    2009.000000  4456.000000  1855.000000  1572.000000  300.000000   \n",
            "\n",
            "         Barley  Buckwheat  \n",
            "count  10.00000       10.0  \n",
            "mean   29.20000       10.0  \n",
            "std     1.47573        0.0  \n",
            "min    28.00000       10.0  \n",
            "25%    28.00000       10.0  \n",
            "50%    28.50000       10.0  \n",
            "75%    30.00000       10.0  \n",
            "max    32.00000       10.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2: Data Wrangling with Pandas"
      ],
      "metadata": {
        "id": "GR3oyLDwtCnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "sales_file_path = '/content/drive/MyDrive/data visualization class/hw/sales_data.csv'\n",
        "product_file_path = '/content/drive/MyDrive/data visualization class/hw/product_data.csv'\n",
        "customer_file_path = '/content/drive/MyDrive/data visualization class/hw/customer_data (1).csv'\n",
        "\n",
        "sales_data = pd.read_csv(sales_file_path)\n",
        "product_data = pd.read_csv(product_file_path)\n",
        "customer_data = pd.read_csv(customer_file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jViYtr-2u2TD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(sales_data.isnull().sum())\n",
        "print(product_data.isnull().sum())\n",
        "print(customer_data.isnull().sum())\n",
        "\n",
        "# Handle missing values (if any)\n",
        "sales_data.fillna(method='ffill', inplace=True)\n",
        "product_data.fillna(method='ffill', inplace=True)\n",
        "customer_data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "sales_data['OrderDate'] = pd.to_datetime(sales_data['OrderDate'])\n",
        "customer_data['CustomerSince'] = pd.to_datetime(customer_data['CustomerSince'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf-VA9zBvfwy",
        "outputId": "7e77e02c-c61f-4918-c547-2a218052b0ce"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderID       0\n",
            "CustomerID    0\n",
            "ProductID     0\n",
            "Quantity      0\n",
            "Price         0\n",
            "OrderDate     0\n",
            "dtype: int64\n",
            "ProductID      0\n",
            "ProductName    0\n",
            "Category       0\n",
            "dtype: int64\n",
            "CustomerID       0\n",
            "CustomerName     0\n",
            "Region           0\n",
            "CustomerSince    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and remove duplicates\n",
        "sales_data = sales_data.drop_duplicates()\n",
        "product_data = product_data.drop_duplicates()\n",
        "customer_data = customer_data.drop_duplicates()\n",
        "\n",
        "# Subset sales data for the last year\n",
        "last_year = pd.Timestamp.now() - pd.DateOffset(years=1)\n",
        "recent_sales = sales_data[sales_data['OrderDate'] >= last_year]\n",
        "\n",
        "# Subset customer data for customers who made a purchase within the last year\n",
        "recent_customer_ids = recent_sales['CustomerID'].unique()\n",
        "recent_customers = customer_data[customer_data['CustomerID'].isin(recent_customer_ids)]\n",
        "\n",
        "# Filter product data for a specified category\n",
        "category = 'Electronics'\n",
        "filtered_products = product_data[product_data['Category'] == category]\n"
      ],
      "metadata": {
        "id": "DFGZWHNNvhkc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Group Analysis"
      ],
      "metadata": {
        "id": "k7XXO9FnvkI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Group Analysis\n",
        "\n",
        "# Merge sales data with customer data\n",
        "merged_data = pd.merge(sales_data, customer_data, on='CustomerID')\n",
        "\n",
        "# Merge the resulting DataFrame with product data\n",
        "merged_data = pd.merge(merged_data, product_data, on='ProductID')"
      ],
      "metadata": {
        "id": "dtZQEclOvVll"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total revenue\n",
        "merged_data['TotalSales'] = merged_data['Quantity'] * merged_data['Price']\n",
        "\n",
        "# Calculate total revenue by region\n",
        "total_revenue_by_region = merged_data.groupby('Region')['TotalSales'].sum()\n",
        "print(\"Total revenue by region:\")\n",
        "print(total_revenue_by_region)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee7ZTaMuvl18",
        "outputId": "cb1f8280-cc3f-4304-bce2-0c89042264b5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total revenue by region:\n",
            "Region\n",
            "East     630002.11\n",
            "North    644408.81\n",
            "South    463993.58\n",
            "West     673403.58\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average and median order value per customer\n",
        "avg_order_value = merged_data.groupby('CustomerID')['TotalSales'].mean()\n",
        "median_order_value = merged_data.groupby('CustomerID')['TotalSales'].median()\n",
        "print(\"\\nAverage order value per customer:\")\n",
        "print(avg_order_value)\n",
        "print(\"\\nMedian order value per customer:\")\n",
        "print(median_order_value)\n",
        "\n",
        "# Top 5 customers by number of orders\n",
        "top_5_customers = merged_data['CustomerID'].value_counts().head(5)\n",
        "print(\"\\nTop 5 customers by number of orders:\")\n",
        "print(top_5_customers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWgafp0avnZ1",
        "outputId": "5ad5e2e2-0343-4b89-f785-8a04e8f40b7f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average order value per customer:\n",
            "CustomerID\n",
            "C0001    2220.416250\n",
            "C0002    2099.790000\n",
            "C0003    1150.862000\n",
            "C0004    3052.744545\n",
            "C0005    1731.320909\n",
            "            ...     \n",
            "C0096    1891.538462\n",
            "C0097    3473.518889\n",
            "C0098    2283.408571\n",
            "C0099    2767.330000\n",
            "C0100     879.900000\n",
            "Name: TotalSales, Length: 100, dtype: float64\n",
            "\n",
            "Median order value per customer:\n",
            "CustomerID\n",
            "C0001    1965.875\n",
            "C0002    1820.430\n",
            "C0003     896.060\n",
            "C0004    2256.840\n",
            "C0005     902.100\n",
            "           ...   \n",
            "C0096     989.650\n",
            "C0097    3779.610\n",
            "C0098    2183.160\n",
            "C0099    2236.000\n",
            "C0100     701.290\n",
            "Name: TotalSales, Length: 100, dtype: float64\n",
            "\n",
            "Top 5 customers by number of orders:\n",
            "CustomerID\n",
            "C0093    19\n",
            "C0083    17\n",
            "C0042    17\n",
            "C0006    16\n",
            "C0094    16\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Merging and Aggregation"
      ],
      "metadata": {
        "id": "FRIijaKZvqKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate total revenue per product category\n",
        "total_revenue_by_category = merged_data.groupby('Category')['TotalSales'].sum()\n",
        "print(\"\\nTotal revenue per product category:\")\n",
        "print(total_revenue_by_category)\n",
        "\n",
        "# Average revenue per order for each region\n",
        "avg_revenue_per_region = merged_data.groupby('Region')['TotalSales'].mean()\n",
        "print(\"\\nAverage revenue per order for each region:\")\n",
        "print(avg_revenue_per_region)\n"
      ],
      "metadata": {
        "id": "4ke2gBxVvZTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Task 5: Advanced Analysis"
      ],
      "metadata": {
        "id": "SGVa4aOovsEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trends in sales over time\n",
        "merged_data['Month'] = merged_data['OrderDate'].dt.to_period('M')\n",
        "monthly_revenue = merged_data.groupby('Month')['TotalSales'].sum()\n",
        "print(\"\\nMonthly revenue:\")\n",
        "print(monthly_revenue)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5y9g_H4vbKg",
        "outputId": "00fcbe7a-d4cc-411e-d716-1880e0c6b616"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Monthly revenue:\n",
            "Month\n",
            "2020-01    45925.90\n",
            "2020-02    38552.93\n",
            "2020-03    68602.02\n",
            "2020-04    47854.90\n",
            "2020-05    38438.79\n",
            "2020-06    54619.50\n",
            "2020-07    35290.61\n",
            "2020-08    55285.86\n",
            "2020-09    45095.04\n",
            "2020-10    43660.12\n",
            "2020-11    38288.16\n",
            "2020-12    48369.69\n",
            "2021-01    39541.12\n",
            "2021-02    66852.06\n",
            "2021-03    51071.48\n",
            "2021-04    62226.90\n",
            "2021-05    52441.83\n",
            "2021-06    55169.93\n",
            "2021-07    43938.26\n",
            "2021-08    73726.95\n",
            "2021-09    27646.51\n",
            "2021-10    36084.77\n",
            "2021-11    67307.57\n",
            "2021-12    35617.36\n",
            "2022-01    49780.18\n",
            "2022-02    34364.33\n",
            "2022-03    73336.70\n",
            "2022-04    49562.01\n",
            "2022-05    40173.91\n",
            "2022-06    28130.50\n",
            "2022-07    56410.26\n",
            "2022-08    88955.53\n",
            "2022-09    60157.85\n",
            "2022-10    50447.87\n",
            "2022-11    52425.72\n",
            "2022-12    47109.01\n",
            "2023-01    63495.05\n",
            "2023-02    44608.67\n",
            "2023-03    75029.43\n",
            "2023-04    49077.91\n",
            "2023-05    36053.71\n",
            "2023-06    61809.77\n",
            "2023-07    29570.86\n",
            "2023-08    59791.15\n",
            "2023-09    54851.94\n",
            "2023-10    46966.50\n",
            "2023-11    33601.69\n",
            "2023-12    54489.27\n",
            "Freq: M, Name: TotalSales, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Churn rate\n",
        "total_customers = customer_data['CustomerID'].nunique()\n",
        "customers_last_year = recent_customers['CustomerID'].nunique()\n",
        "churn_rate = (total_customers - customers_last_year) / total_customers\n",
        "print(f\"\\nChurn rate: {churn_rate:.2%}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFopN6HFvuqs",
        "outputId": "3cd56cbd-b231-4ccf-e02e-a5a2e8808883"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Churn rate: 35.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cohort analysis\n",
        "first_purchase = merged_data.groupby('CustomerID')['OrderDate'].min().reset_index()\n",
        "first_purchase['CohortMonth'] = first_purchase['OrderDate'].dt.to_period('M')\n",
        "cohort_data = pd.merge(merged_data, first_purchase, on='CustomerID')\n",
        "cohort_data['CohortIndex'] = ((cohort_data['OrderDate_x'] - cohort_data['OrderDate_y']).dt.days // 30) + 1\n",
        "cohort_grouped = cohort_data.groupby(['CohortMonth', 'CohortIndex'])['CustomerID'].nunique().unstack(0)\n",
        "print(\"\\nCohort analysis:\")\n",
        "print(cohort_grouped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnDR3BtGvv8c",
        "outputId": "c9f7b6a9-ad1c-49ba-c91b-806083ebd745"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cohort analysis:\n",
            "CohortMonth  2020-01  2020-02  2020-03  2020-04  2020-05  2020-06  2020-07  \\\n",
            "CohortIndex                                                                  \n",
            "1               20.0     15.0     14.0     11.0     12.0      4.0      3.0   \n",
            "2                6.0      4.0      1.0      1.0      3.0      1.0      NaN   \n",
            "3                3.0      1.0      2.0      3.0      5.0      NaN      1.0   \n",
            "4                6.0      3.0      7.0      1.0      2.0      2.0      1.0   \n",
            "5                2.0      NaN      NaN      1.0      1.0      NaN      NaN   \n",
            "6                5.0      3.0      1.0      2.0      5.0      1.0      NaN   \n",
            "7                5.0      3.0      3.0      2.0      1.0      1.0      NaN   \n",
            "8                3.0      5.0      1.0      NaN      1.0      NaN      2.0   \n",
            "9                7.0      2.0      1.0      2.0      3.0      1.0      NaN   \n",
            "10               3.0      3.0      2.0      1.0      3.0      1.0      1.0   \n",
            "11               2.0      4.0      2.0      2.0      1.0      NaN      NaN   \n",
            "12               4.0      3.0      2.0      2.0      1.0      1.0      NaN   \n",
            "13               6.0      3.0      3.0      3.0      1.0      NaN      NaN   \n",
            "14               1.0      3.0      4.0      2.0      5.0      NaN      NaN   \n",
            "15               3.0      6.0      4.0      2.0      1.0      NaN      NaN   \n",
            "16               4.0      4.0      2.0      1.0      2.0      1.0      1.0   \n",
            "17               7.0      3.0      5.0      2.0      NaN      1.0      NaN   \n",
            "18               5.0      5.0      2.0      NaN      3.0      1.0      NaN   \n",
            "19               6.0      2.0      1.0      2.0      3.0      NaN      NaN   \n",
            "20               2.0      3.0      1.0      4.0      1.0      NaN      NaN   \n",
            "21               5.0      4.0      1.0      1.0      2.0      NaN      NaN   \n",
            "22               4.0      1.0      4.0      2.0      2.0      NaN      NaN   \n",
            "23               5.0      5.0      1.0      1.0      2.0      NaN      NaN   \n",
            "24               1.0      4.0      4.0      1.0      5.0      NaN      NaN   \n",
            "25               2.0      3.0      4.0      2.0      3.0      2.0      NaN   \n",
            "26               1.0      2.0      2.0      2.0      3.0      1.0      1.0   \n",
            "27               2.0      3.0      2.0      1.0      3.0      NaN      NaN   \n",
            "28               4.0      3.0      1.0      2.0      2.0      2.0      3.0   \n",
            "29               5.0      1.0      4.0      2.0      1.0      NaN      1.0   \n",
            "30               2.0      2.0      3.0      1.0      2.0      1.0      1.0   \n",
            "31               3.0      NaN      4.0      1.0      3.0      2.0      1.0   \n",
            "32               5.0      4.0      2.0      1.0      3.0      NaN      1.0   \n",
            "33               5.0      4.0      4.0      3.0      1.0      3.0      2.0   \n",
            "34               5.0      3.0      1.0      2.0      1.0      NaN      NaN   \n",
            "35               2.0      4.0      3.0      2.0      4.0      1.0      NaN   \n",
            "36               2.0      7.0      2.0      1.0      4.0      1.0      1.0   \n",
            "37               1.0      4.0      2.0      3.0      2.0      1.0      NaN   \n",
            "38               5.0      3.0      3.0      2.0      1.0      1.0      NaN   \n",
            "39               7.0      6.0      2.0      2.0      2.0      1.0      1.0   \n",
            "40               2.0      2.0      3.0      2.0      3.0      1.0      NaN   \n",
            "41               4.0      2.0      1.0      1.0      1.0      1.0      NaN   \n",
            "42               3.0      2.0      2.0      3.0      4.0      NaN      1.0   \n",
            "43               2.0      5.0      3.0      1.0      2.0      1.0      NaN   \n",
            "44               1.0      1.0      NaN      3.0      NaN      NaN      NaN   \n",
            "45               2.0      2.0      NaN      5.0      1.0      NaN      NaN   \n",
            "46               2.0      4.0      2.0      NaN      NaN      NaN      NaN   \n",
            "47               2.0      3.0      NaN      NaN      NaN      NaN      NaN   \n",
            "48               3.0      2.0      NaN      NaN      NaN      NaN      NaN   \n",
            "49               1.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "\n",
            "CohortMonth  2020-08  2020-09  2020-10  2020-12  2021-02  2021-03  2021-06  \\\n",
            "CohortIndex                                                                  \n",
            "1                3.0      7.0      2.0      1.0      1.0      2.0      1.0   \n",
            "2                NaN      1.0      NaN      NaN      1.0      NaN      NaN   \n",
            "3                NaN      1.0      NaN      NaN      NaN      1.0      NaN   \n",
            "4                1.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "5                NaN      NaN      NaN      NaN      NaN      1.0      NaN   \n",
            "6                1.0      5.0      1.0      NaN      1.0      1.0      NaN   \n",
            "7                NaN      1.0      1.0      NaN      NaN      NaN      NaN   \n",
            "8                1.0      2.0      1.0      NaN      NaN      NaN      NaN   \n",
            "9                2.0      1.0      1.0      NaN      NaN      NaN      NaN   \n",
            "10               2.0      NaN      NaN      NaN      NaN      1.0      NaN   \n",
            "11               NaN      2.0      NaN      NaN      1.0      1.0      NaN   \n",
            "12               1.0      1.0      NaN      1.0      NaN      1.0      NaN   \n",
            "13               NaN      1.0      NaN      NaN      NaN      1.0      NaN   \n",
            "14               NaN      NaN      1.0      NaN      NaN      2.0      NaN   \n",
            "15               1.0      1.0      1.0      NaN      NaN      NaN      1.0   \n",
            "16               NaN      NaN      NaN      NaN      1.0      NaN      NaN   \n",
            "17               NaN      3.0      NaN      NaN      NaN      1.0      1.0   \n",
            "18               1.0      NaN      NaN      NaN      NaN      2.0      NaN   \n",
            "19               1.0      2.0      1.0      NaN      1.0      NaN      NaN   \n",
            "20               1.0      1.0      NaN      1.0      NaN      NaN      NaN   \n",
            "21               NaN      1.0      NaN      NaN      1.0      NaN      NaN   \n",
            "22               NaN      2.0      NaN      1.0      1.0      NaN      NaN   \n",
            "23               NaN      3.0      NaN      NaN      NaN      NaN      NaN   \n",
            "24               NaN      3.0      NaN      1.0      NaN      1.0      NaN   \n",
            "25               1.0      3.0      NaN      NaN      1.0      NaN      1.0   \n",
            "26               2.0      2.0      NaN      1.0      NaN      NaN      NaN   \n",
            "27               1.0      1.0      NaN      1.0      NaN      NaN      NaN   \n",
            "28               2.0      1.0      1.0      NaN      NaN      1.0      1.0   \n",
            "29               1.0      3.0      NaN      1.0      1.0      NaN      NaN   \n",
            "30               1.0      1.0      NaN      NaN      NaN      NaN      NaN   \n",
            "31               NaN      NaN      NaN      NaN      1.0      NaN      NaN   \n",
            "32               1.0      1.0      NaN      NaN      NaN      NaN      NaN   \n",
            "33               1.0      1.0      NaN      NaN      NaN      2.0      NaN   \n",
            "34               1.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "35               1.0      2.0      1.0      NaN      NaN      NaN      NaN   \n",
            "36               1.0      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "37               NaN      1.0      NaN      NaN      NaN      NaN      NaN   \n",
            "38               2.0      1.0      NaN      NaN      NaN      NaN      NaN   \n",
            "39               NaN      3.0      NaN      NaN      NaN      NaN      NaN   \n",
            "40               1.0      2.0      NaN      NaN      NaN      NaN      NaN   \n",
            "41               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "42               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "43               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "44               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "45               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "46               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "47               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "48               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "49               NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
            "\n",
            "CohortMonth  2021-10  2021-11  2021-12  \n",
            "CohortIndex                             \n",
            "1                1.0      2.0      1.0  \n",
            "2                NaN      1.0      1.0  \n",
            "3                NaN      NaN      1.0  \n",
            "4                NaN      NaN      NaN  \n",
            "5                NaN      NaN      1.0  \n",
            "6                NaN      NaN      NaN  \n",
            "7                NaN      NaN      NaN  \n",
            "8                NaN      NaN      NaN  \n",
            "9                NaN      1.0      NaN  \n",
            "10               NaN      NaN      NaN  \n",
            "11               NaN      NaN      1.0  \n",
            "12               NaN      NaN      NaN  \n",
            "13               1.0      NaN      NaN  \n",
            "14               NaN      NaN      NaN  \n",
            "15               NaN      NaN      NaN  \n",
            "16               NaN      NaN      NaN  \n",
            "17               NaN      1.0      1.0  \n",
            "18               NaN      NaN      NaN  \n",
            "19               NaN      1.0      NaN  \n",
            "20               NaN      NaN      1.0  \n",
            "21               NaN      1.0      NaN  \n",
            "22               NaN      NaN      NaN  \n",
            "23               NaN      NaN      NaN  \n",
            "24               NaN      1.0      1.0  \n",
            "25               NaN      NaN      NaN  \n",
            "26               NaN      NaN      NaN  \n",
            "27               NaN      NaN      NaN  \n",
            "28               NaN      NaN      NaN  \n",
            "29               NaN      NaN      NaN  \n",
            "30               NaN      NaN      NaN  \n",
            "31               NaN      NaN      NaN  \n",
            "32               NaN      NaN      NaN  \n",
            "33               NaN      NaN      NaN  \n",
            "34               NaN      NaN      NaN  \n",
            "35               NaN      NaN      NaN  \n",
            "36               NaN      NaN      NaN  \n",
            "37               NaN      NaN      NaN  \n",
            "38               NaN      NaN      NaN  \n",
            "39               NaN      NaN      NaN  \n",
            "40               NaN      NaN      NaN  \n",
            "41               NaN      NaN      NaN  \n",
            "42               NaN      NaN      NaN  \n",
            "43               NaN      NaN      NaN  \n",
            "44               NaN      NaN      NaN  \n",
            "45               NaN      NaN      NaN  \n",
            "46               NaN      NaN      NaN  \n",
            "47               NaN      NaN      NaN  \n",
            "48               NaN      NaN      NaN  \n",
            "49               NaN      NaN      NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6: Reporting and Interpretation"
      ],
      "metadata": {
        "id": "P6aDAqBjvcj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Findings: After analyzing sales data from January to June 2024, we found that overall sales have been increasing steadily month over month. Category A products, particularly premium items, consistently lead in sales volume and revenue generation. Our data also identifies two main customer segments: those inclined towards purchasing high-value items and those who respond favorably to promotional discounts.\n",
        "\n",
        "Actionable Insights: To maximize revenue, focusing on promoting high-profit Category A products is crucial. Tailoring marketing strategies to appeal directly to each customer segment—emphasizing premium products to one group and highlighting discounts to another—can significantly boost sales.\n",
        "\n",
        "Limitations: Our analysis is limited by the lack of detailed customer demographics and behavior data. Additionally, seasonal fluctuations impact sales trends, warranting further investigation.\n",
        "\n",
        "Improvements: Gathering more comprehensive customer data through surveys or feedback mechanisms could enhance our understanding of consumer preferences. Additionally, analyzing economic indicators alongside sales data could provide deeper insights into fluctuating sales patterns."
      ],
      "metadata": {
        "id": "-VPeh61Owgy-"
      }
    }
  ]
}